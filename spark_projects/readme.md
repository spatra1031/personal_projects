# Apache Spark Projects ğŸš€
Big Data | Distributed Computing | PySpark | Scala | Data Engineering

Welcome to my Apache Spark projects repository! ğŸ¯ This collection of projects showcases my ability to work with large-scale datasets, process data efficiently using Sparkâ€™s distributed computing power, and derive meaningful insights.

Each project focuses on solving a real-world problem, covering domains like transportation, emergency response, data aggregation, and salary analysis. Iâ€™ve used both PySpark and Scala to implement various data transformations, analytics, and optimizations.

## ğŸ“‚ Projects Overview

### 1ï¸âƒ£ Flight Delays Analysis âœˆï¸
ğŸ“Œ Objective: Analyze flight departure delays across the US using Apache Spark.
ğŸ”¹ Key Highlights:
âœ… Query flight delays using Spark SQL and DataFrame API
âœ… Find flights delayed over 120 minutes from SFO to ORD
âœ… Store processed data in Parquet & JSON formats for optimized retrieval
âœ… Identify the busiest months and routes for better decision-making

ğŸ› ï¸ Tech Stack: Spark SQL | DataFrames | PySpark | Parquet | JSON

ğŸ”— [Code](https://github.com/spatra1031/personal_projects/tree/main/spark_projects/flights_delay)

### 2ï¸âƒ£ M&M Candy Count Analysis ğŸ¬
ğŸ“Œ Objective: Analyze the distribution of M&M candy colors across different states.
ğŸ”¹ Key Highlights:
âœ… Aggregates the total count of each M&M color per state
âœ… Identifies the most popular candy color nationwide
âœ… Filters data to analyze trends specific to California (CA)

ğŸ› ï¸ Tech Stack: PySpark | Data Aggregation | DataFrames

ğŸ”— [Code](https://github.com/spatra1031/personal_projects/tree/main/spark_projects/mnm_count)

### 3ï¸âƒ£ San Francisco Fire Calls Analysis ğŸš’
ğŸ“Œ Objective: Perform exploratory data analysis on fire department emergency calls in San Francisco.
ğŸ”¹ Key Insights Uncovered:
âœ… Identifies the most common fire emergency types in 2018
âœ… Determines the busiest month for fire calls and week with the highest incidents
âœ… Analyzes neighborhoods with the worst emergency response times ğŸš‘
âœ… Stores structured data in Parquet format for efficient querying

ğŸ› ï¸ Tech Stack: PySpark | Spark SQL | Data Aggregation | Parquet

ğŸ”— [Code](https://github.com/spatra1031/personal_projects/tree/main/spark_projects/sanfrancisco_firecalls)

### 4ï¸âƒ£ Divvy Bike Trips Analysis ğŸš´
ğŸ“Œ Objective: Analyze bike-sharing trends in Chicago using Divvy bike trip data.
ğŸ”¹ Key Insights Uncovered:
âœ… Identifies the most frequently used bike stations and routes
âœ… Calculates the average trip duration by user type (casual vs. subscriber)
âœ… Determines the peak hours for bike rentals based on historical data

ğŸ› ï¸ Tech Stack: PySpark | Spark SQL | DataFrames | Data Aggregation

ğŸ”— [Code](https://github.com/spatra1031/personal_projects/tree/main/spark_projects/divvy_trips)

### 5ï¸âƒ£ Employee Salary Analysis ğŸ’¼
ğŸ“Œ Objective: Perform salary data analysis to gain insights into workforce compensation.
ğŸ”¹ Key Findings:
âœ… Computes the average salary by department and job role
âœ… Analyzes salary distribution and identifies top-paying job positions
âœ… Examines potential gender-based salary disparities

ğŸ› ï¸ Tech Stack: PySpark | Spark SQL | DataFrames | Statistical Analysis

[ğŸ”— Code](https://github.com/spatra1031/personal_projects/tree/main/spark_projects/flights_delay)

### ğŸ› ï¸ Tech Stack & Tools Used
ğŸš€ Apache Spark â€“ High-performance distributed computing
ğŸ PySpark â€“ Python API for Spark
ğŸ“Š Spark SQL â€“ Querying and analyzing structured data

### ğŸ“‚ DataFrames & Datasets â€“ Efficient data manipulation
ğŸ“ Scala â€“ Optimized Spark programming
ğŸ—„ï¸ Parquet & JSON â€“ Scalable data storage

### ğŸ”® Future Enhancements & Next Steps
âœ”ï¸ Real-time streaming analysis using Apache Kafka
âœ”ï¸ Predictive modeling for flight delays using ML algorithms
âœ”ï¸ Geospatial visualization of fire calls with mapping tools
âœ”ï¸ Enhanced analytics for Divvy bike-sharing trends ğŸš´

### ğŸ’¡ Why This Repository?
ğŸ’¡ If you're interested in big data analytics, distributed computing, or Apache Spark, this repository provides hands-on examples with real-world datasets. Each project demonstrates:
âœ… Efficient data processing techniques
âœ… Optimized querying with Spark SQL
âœ… Best practices for storing and handling large datasets

Whether you're a data scientist, engineer, or analyst, these projects will help you understand how to leverage Spark for large-scale data processing.

