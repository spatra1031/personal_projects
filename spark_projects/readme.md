# Apache Spark Projects 🚀
Big Data | Distributed Computing | PySpark | Scala | Data Engineering

Welcome to my Apache Spark projects repository! 🎯 This collection of projects showcases my ability to work with large-scale datasets, process data efficiently using Spark’s distributed computing power, and derive meaningful insights.

Each project focuses on solving a real-world problem, covering domains like transportation, emergency response, data aggregation, and salary analysis. I’ve used both PySpark and Scala to implement various data transformations, analytics, and optimizations.

## 📂 Projects Overview

### 1️⃣ Flight Delays Analysis ✈️
📌 Objective: Analyze flight departure delays across the US using Apache Spark.
🔹 Key Highlights:
✅ Query flight delays using Spark SQL and DataFrame API
✅ Find flights delayed over 120 minutes from SFO to ORD
✅ Store processed data in Parquet & JSON formats for optimized retrieval
✅ Identify the busiest months and routes for better decision-making

🛠️ Tech Stack: Spark SQL | DataFrames | PySpark | Parquet | JSON

🔗 [Code](https://github.com/spatra1031/personal_projects/tree/main/spark_projects/flights_delay)

### 2️⃣ M&M Candy Count Analysis 🍬
📌 Objective: Analyze the distribution of M&M candy colors across different states.
🔹 Key Highlights:
✅ Aggregates the total count of each M&M color per state
✅ Identifies the most popular candy color nationwide
✅ Filters data to analyze trends specific to California (CA)

🛠️ Tech Stack: PySpark | Data Aggregation | DataFrames

🔗 [Code](https://github.com/spatra1031/personal_projects/tree/main/spark_projects/mnm_count)

### 3️⃣ San Francisco Fire Calls Analysis 🚒
📌 Objective: Perform exploratory data analysis on fire department emergency calls in San Francisco.
🔹 Key Insights Uncovered:
✅ Identifies the most common fire emergency types in 2018
✅ Determines the busiest month for fire calls and week with the highest incidents
✅ Analyzes neighborhoods with the worst emergency response times 🚑
✅ Stores structured data in Parquet format for efficient querying

🛠️ Tech Stack: PySpark | Spark SQL | Data Aggregation | Parquet

🔗 [Code](https://github.com/spatra1031/personal_projects/tree/main/spark_projects/sanfrancisco_firecalls)

### 4️⃣ Divvy Bike Trips Analysis 🚴
📌 Objective: Analyze bike-sharing trends in Chicago using Divvy bike trip data.
🔹 Key Insights Uncovered:
✅ Identifies the most frequently used bike stations and routes
✅ Calculates the average trip duration by user type (casual vs. subscriber)
✅ Determines the peak hours for bike rentals based on historical data

🛠️ Tech Stack: PySpark | Spark SQL | DataFrames | Data Aggregation

🔗 [Code](https://github.com/spatra1031/personal_projects/tree/main/spark_projects/divvy_trips)

### 5️⃣ Employee Salary Analysis 💼
📌 Objective: Perform salary data analysis to gain insights into workforce compensation.
🔹 Key Findings:
✅ Computes the average salary by department and job role
✅ Analyzes salary distribution and identifies top-paying job positions
✅ Examines potential gender-based salary disparities

🛠️ Tech Stack: PySpark | Spark SQL | DataFrames | Statistical Analysis

[🔗 Code](https://github.com/spatra1031/personal_projects/tree/main/spark_projects/flights_delay)

### 🛠️ Tech Stack & Tools Used
🚀 Apache Spark – High-performance distributed computing
🐍 PySpark – Python API for Spark
📊 Spark SQL – Querying and analyzing structured data

### 📂 DataFrames & Datasets – Efficient data manipulation
📝 Scala – Optimized Spark programming
🗄️ Parquet & JSON – Scalable data storage

### 🔮 Future Enhancements & Next Steps
✔️ Real-time streaming analysis using Apache Kafka
✔️ Predictive modeling for flight delays using ML algorithms
✔️ Geospatial visualization of fire calls with mapping tools
✔️ Enhanced analytics for Divvy bike-sharing trends 🚴

### 💡 Why This Repository?
💡 If you're interested in big data analytics, distributed computing, or Apache Spark, this repository provides hands-on examples with real-world datasets. Each project demonstrates:
✅ Efficient data processing techniques
✅ Optimized querying with Spark SQL
✅ Best practices for storing and handling large datasets

Whether you're a data scientist, engineer, or analyst, these projects will help you understand how to leverage Spark for large-scale data processing.

